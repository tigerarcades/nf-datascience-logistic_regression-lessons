{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we’ll take advantage of the make_classification function from the scikit-learn library to generate data. As we mentioned previously, \n",
    "#Logistic Regression is only applicable to binary classification problems. \n",
    "#Thus, the data points are composed of two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=100,\n",
    "    n_features=1,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    flip_y=0.03,\n",
    "    n_informative=1,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x116d6bf60>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We plot the relationship between the feature and classes.\n",
    "plt.scatter(x, y, c=y, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prior to training our model, we’ll set aside a portion of our data in order to evaluate its performance.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We instantiate an instance of the LogisticRegression class and call the fit function with the features and the labels (since Logistic Regression is a\n",
    "#supervised machine learning algorithm) as arguments.\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.62632685]]\n",
      "[-0.67445391]\n"
     ]
    }
   ],
   "source": [
    "#We can access the following properties to actually view the coefficient for the slope and y-intercept of the best fitting line.\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let’s see how the model performs against data that it hasn’t been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  2],\n",
       "       [ 0, 13]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given that this consists of a classification problem, \n",
    "#we use a confusion matrix to measure the accuracy of our model.\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14523978, 0.85476022],\n",
       "       [0.63543584, 0.36456416],\n",
       "       [0.88258525, 0.11741475],\n",
       "       [0.99577826, 0.00422174],\n",
       "       [0.7745509 , 0.2254491 ],\n",
       "       [0.14065575, 0.85934425],\n",
       "       [0.45415786, 0.54584214],\n",
       "       [0.1276361 , 0.8723639 ],\n",
       "       [0.07135595, 0.92864405],\n",
       "       [0.94038378, 0.05961622],\n",
       "       [0.08803493, 0.91196507],\n",
       "       [0.14580049, 0.85419951],\n",
       "       [0.07293242, 0.92706758],\n",
       "       [0.43192407, 0.56807593],\n",
       "       [0.16031041, 0.83968959],\n",
       "       [0.03297248, 0.96702752],\n",
       "       [0.11386981, 0.88613019],\n",
       "       [0.9973331 , 0.0026669 ],\n",
       "       [0.78837851, 0.21162149],\n",
       "       [0.48612192, 0.51387808],\n",
       "       [0.15125306, 0.84874694],\n",
       "       [0.75047873, 0.24952127],\n",
       "       [0.23233382, 0.76766618],\n",
       "       [0.99593378, 0.00406622],\n",
       "       [0.97640103, 0.02359897]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If for whatever reason we’d like to check the actual probability that a data \n",
    "#point belongs to a given class, \n",
    "#we can use the predict_proba function.\n",
    "\n",
    "lr.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The first column corresponds to the \n",
    "#probability that the sample belongs to the first class and the\n",
    "#second column corresponds to the probability that the \n",
    "#sample belongs to the second class.\n",
    "#Before attempting to plot the Sigmoid function, we create and sort a DataFrame containing our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x116d98828>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'x': x_test[:,0], 'y': y_test})\n",
    "df = df.sort_values(by='x')\n",
    "from scipy.special import expit\n",
    "sigmoid_function = expit(df['x'] * lr.coef_[0][0] + lr.intercept_[0]).ravel()\n",
    "plt.plot(df['x'], sigmoid_function)\n",
    "plt.scatter(df['x'], df['y'], c=df['y'], cmap='rainbow', edgecolors='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: -c: line 0: syntax error near unexpected token `'pic.png''\r\n",
      "/bin/sh: -c: line 0: `[title]('pic.png')'\r\n"
     ]
    }
   ],
   "source": [
    "![title]('pic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
